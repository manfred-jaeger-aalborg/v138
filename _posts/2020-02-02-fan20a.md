---
section: Research Papers
title: " Contrastive Divergence Learning with Chained Belief Propagation"
abstract: "Contrastive Divergence (CD) is an important maximum-likelihood learning
  approach for probabilistic graphical models. CD maximizes the difference in likelihood
  between the observed data and those sampled from the current model distribution
  using Markov Chain Monte Carlo (MCMC). Nevertheless, the overall performance of
  CD is hampered by the slow mixing rate of MCMC in the presence of combinatorial
  constraints. A competing approach BP-CD replaces MCMC with Belief Propagation (BP).
  However, their samples are generated from a mean-field \r approximation, which may
  be far away from the true distribution. Here we propose contrastive divergence learning
  with chained belief propagation (BPChain-CD). To generate one sample in CD, we fix
  one variable at a time based on the marginal distribution computed by BP conditioned
  on previous variables. We analyze BPChain-CD both theoretically and experimentally.
  We show that BPChain-CD learns better models compared with  BP-CD and CD on a range
  of maximum-likelihood learning experiments."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fan20a
month: 0
tex_title: " Contrastive Divergence Learning with Chained Belief Propagation"
firstpage: 161
lastpage: 172
page: 161-172
order: 161
cycles: false
bibtex_author: Fan, Ding and Yexiang, Xue
author:
- given: Ding
  family: Fan
- given: Xue
  family: Yexiang
date: 2020-02-02
address: 
container-title: Proceedings of the 10th International Conference on Probabilistic
  Graphical Models
volume: '138'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 2
pdf: http://proceedings.mlr.press/v138/fan20a/fan20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
